{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import tensorflow as tf\n",
    "from tensorflow import keras\n",
    "import cv2\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = keras.models.load_model(\n",
    "    filepath=\"../LaneNet/full_CNN_model.h5\")\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " batch_normalization (BatchN  (None, 80, 160, 3)       12        \n",
      " ormalization)                                                   \n",
      "                                                                 \n",
      " Conv1 (Conv2D)              (None, 78, 158, 8)        224       \n",
      "                                                                 \n",
      " Conv2 (Conv2D)              (None, 76, 156, 16)       1168      \n",
      "                                                                 \n",
      " max_pooling2d (MaxPooling2D  (None, 38, 78, 16)       0         \n",
      " )                                                               \n",
      "                                                                 \n",
      " Conv3 (Conv2D)              (None, 36, 76, 16)        2320      \n",
      "                                                                 \n",
      " dropout (Dropout)           (None, 36, 76, 16)        0         \n",
      "                                                                 \n",
      " Conv4 (Conv2D)              (None, 34, 74, 32)        4640      \n",
      "                                                                 \n",
      " dropout_1 (Dropout)         (None, 34, 74, 32)        0         \n",
      "                                                                 \n",
      " Conv5 (Conv2D)              (None, 32, 72, 32)        9248      \n",
      "                                                                 \n",
      " dropout_2 (Dropout)         (None, 32, 72, 32)        0         \n",
      "                                                                 \n",
      " max_pooling2d_1 (MaxPooling  (None, 16, 36, 32)       0         \n",
      " 2D)                                                             \n",
      "                                                                 \n",
      " Conv6 (Conv2D)              (None, 14, 34, 64)        18496     \n",
      "                                                                 \n",
      " dropout_3 (Dropout)         (None, 14, 34, 64)        0         \n",
      "                                                                 \n",
      " Conv7 (Conv2D)              (None, 12, 32, 64)        36928     \n",
      "                                                                 \n",
      " dropout_4 (Dropout)         (None, 12, 32, 64)        0         \n",
      "                                                                 \n",
      " max_pooling2d_2 (MaxPooling  (None, 6, 16, 64)        0         \n",
      " 2D)                                                             \n",
      "                                                                 \n",
      " up_sampling2d (UpSampling2D  (None, 12, 32, 64)       0         \n",
      " )                                                               \n",
      "                                                                 \n",
      " Deconv1 (Conv2DTranspose)   (None, 14, 34, 64)        36928     \n",
      "                                                                 \n",
      " dropout_5 (Dropout)         (None, 14, 34, 64)        0         \n",
      "                                                                 \n",
      " Deconv2 (Conv2DTranspose)   (None, 16, 36, 64)        36928     \n",
      "                                                                 \n",
      " dropout_6 (Dropout)         (None, 16, 36, 64)        0         \n",
      "                                                                 \n",
      " up_sampling2d_1 (UpSampling  (None, 32, 72, 64)       0         \n",
      " 2D)                                                             \n",
      "                                                                 \n",
      " Deconv3 (Conv2DTranspose)   (None, 34, 74, 32)        18464     \n",
      "                                                                 \n",
      " dropout_7 (Dropout)         (None, 34, 74, 32)        0         \n",
      "                                                                 \n",
      " Deconv4 (Conv2DTranspose)   (None, 36, 76, 32)        9248      \n",
      "                                                                 \n",
      " dropout_8 (Dropout)         (None, 36, 76, 32)        0         \n",
      "                                                                 \n",
      " Deconv5 (Conv2DTranspose)   (None, 38, 78, 16)        4624      \n",
      "                                                                 \n",
      " dropout_9 (Dropout)         (None, 38, 78, 16)        0         \n",
      "                                                                 \n",
      " up_sampling2d_2 (UpSampling  (None, 76, 156, 16)      0         \n",
      " 2D)                                                             \n",
      "                                                                 \n",
      " Deconv6 (Conv2DTranspose)   (None, 78, 158, 16)       2320      \n",
      "                                                                 \n",
      " Final (Conv2DTranspose)     (None, 80, 160, 1)        145       \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 181,693\n",
      "Trainable params: 181,687\n",
      "Non-trainable params: 6\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "image=cv2.imread(\"../images/test_image.jpg\")\n",
    "def resize_image(image):\n",
    "    #print(image.shape)\n",
    "    image=cv2.resize(image,(160,80))\n",
    "    #print(image.shape)\n",
    "    small_img = cv2.resize(image, (160, 80)) \n",
    "    #print(plt.imshow(image))\n",
    "    small_img = np.array(small_img)\n",
    "    small_img = small_img[None, :, :, :]\n",
    "    return small_img,image\n",
    "    #print(small_img.shape)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Exception ignored in: <function ScopedTFGraph.__del__ at 0x000001BD28F08C10>\n",
      "Traceback (most recent call last):\n",
      "  File \"C:\\Users\\delwy\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.9_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python39\\site-packages\\tensorflow\\python\\framework\\c_api_util.py\", line 54, in __del__\n",
      "    self.deleter(self.graph)\n",
      "AttributeError: deleter\n"
     ]
    }
   ],
   "source": [
    "vid = cv2.VideoCapture(\"../videos/solidWhiteRight.mp4\")\n",
    "while(vid.isOpened()):\n",
    "    ret, image = vid.read()\n",
    "\n",
    "    if ret == True:\n",
    "        small_img,image=resize_image(image)\n",
    "        res = model.predict(small_img)\n",
    "        lane = res[0]*255\n",
    "        blanks = np.zeros((lane.shape[0], lane.shape[1], 3))\n",
    "        blanks[:, :, 1] = blanks[:, :, 1]+lane[:, :, 0]\n",
    "        \n",
    "        lane_image = blanks.astype('uint8')\n",
    "        \n",
    "        \n",
    "        result = cv2.addWeighted(image, 1, lane_image, 1, 0)\n",
    "        cv2.imshow('result',result)\n",
    "        #print(plt.imshow(result))\n",
    "        if(cv2.waitKey(1) == ord('q')):\n",
    "            break\n",
    "    else:\n",
    "        break\n",
    "\n",
    "\n",
    "        \n",
    "   \n",
    "vid.release()\n",
    "cv2.destroyAllWindows()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.9.13 64-bit (microsoft store)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.13"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "5e43a9a6a46b72a562f7cc9e0a95158ec87a580a2cb1ca7ab0b6c0b02e890d27"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
